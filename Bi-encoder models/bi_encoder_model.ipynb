{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aad97e32-2914-4b94-bda0-6c2a1cedcd3a"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "from typing import Callable, Iterable\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import datasets\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from tqdm import tqdm\n",
        "from transformers import BertTokenizerFast, BertModel\n",
        "from transformers.optimization import get_linear_schedule_with_warmup\n",
        "from scipy import stats\n",
        "from sklearn.metrics.pairwise import cosine_similarity"
      ],
      "id": "aad97e32-2914-4b94-bda0-6c2a1cedcd3a"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 100,
          "referenced_widgets": [
            "ee6f0e8f482a489f8872e7533650ece0",
            "998c8e2f043941ce88ce81dd7115eaba",
            "fd6538776c014607a05e6c7509b9d804",
            "222ad898257f4d2184d4dbce267f0227",
            "c42bd8877dd543bea98f50fe86fc1ce0",
            "f5fd8c9b723640d3b9bac3958569af24",
            "6324a7454ece41b9a2f50845499282f2",
            "04c2f8b2d86040c08c34971f31a305f0",
            "9a8ccbdc79854684a9d70178e2183082",
            "c88988f31a49457a9d41d9fad5e4496e",
            "c8884bcd07f240e3b6e4294fe8d93002"
          ]
        },
        "id": "89b4feb7-a12b-45d3-8389-d15444836c32",
        "outputId": "0108e091-5f7b-4cb8-cb45-ec410a446891"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ee6f0e8f482a489f8872e7533650ece0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2348/2348 [00:00<00:00, 16510.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "45.49574105621806\n",
            "158.80706984667802\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "tokenizer = BertTokenizerFast.from_pretrained(\"bert-base-uncased\")\n",
        "seed = 10\n",
        "\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "\n",
        "dataset = datasets.load_dataset(\"csv\", data_files= 'paired_annotations.csv')\n",
        "dataset['train'][0]\n",
        "student_lengths, teacher_legnths = [], []\n",
        "\n",
        "for data in tqdm(dataset['train']):\n",
        "    #if random.random() > 0.9:\n",
        "    student_lengths.append(len(data[\"student_text\"]))\n",
        "    teacher_legnths.append(len(data[\"teacher_text\"]))\n",
        "\n",
        "print(np.mean(student_lengths)); print(np.mean(teacher_legnths))"
      ],
      "id": "89b4feb7-a12b-45d3-8389-d15444836c32"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "43e9698f-ce73-45a5-8684-bd44c0d0e7a1",
        "outputId": "d99486c2-1107-4302-fd0d-5b4395f7c3a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 1.15 s, sys: 203 ms, total: 1.35 s\n",
            "Wall time: 615 ms\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "MAX_LENGTH = 128\n",
        "\n",
        "tokenized_premises = tokenizer([data[\"student_text\"] for data in dataset['train']],\n",
        "                               max_length=MAX_LENGTH, padding=\"max_length\",\n",
        "                               truncation=True, verbose=True)\n",
        "\n",
        "tokenized_hypothesis = tokenizer([data[\"teacher_text\"] for data in dataset['train']],\n",
        "                                 max_length=MAX_LENGTH, padding=\"max_length\",\n",
        "                                 truncation=True, verbose=True)"
      ],
      "id": "43e9698f-ce73-45a5-8684-bd44c0d0e7a1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1b46bf79-b115-4028-9826-5b18ff3837cd"
      },
      "outputs": [],
      "source": [
        "class Dataset(Dataset):\n",
        "    def __init__(self, premise_tokens: dict, hypothesis_tokens: dict, labels: Iterable[str]):\n",
        "        self.premise_tokens = premise_tokens\n",
        "        self.hypothesis_tokens = hypothesis_tokens\n",
        "        self.labels = labels\n",
        "        self._init_data()\n",
        "\n",
        "    def _init_data(self) -> None:\n",
        "        self.data = []\n",
        "        for pt_ids, pt_am, ht_ids, ht_am, label in zip(\n",
        "            self.premise_tokens[\"input_ids\"], self.premise_tokens[\"attention_mask\"],\n",
        "            self.hypothesis_tokens[\"input_ids\"], self.hypothesis_tokens[\"attention_mask\"],\n",
        "            self.labels\n",
        "        ):\n",
        "            data = {}\n",
        "            data[\"premise_input_ids\"] = torch.tensor(pt_ids, dtype=torch.long)\n",
        "            data[\"premise_attention_mask\"] = torch.tensor(pt_am, dtype=torch.long)\n",
        "            data[\"hypothesis_input_ids\"] = torch.tensor(ht_ids, dtype=torch.long)\n",
        "            data[\"hypothesis_attention_mask\"] = torch.tensor(ht_am, dtype=torch.long)\n",
        "            data[\"label\"] = torch.tensor(label, dtype=torch.long)\n",
        "            self.data.append(data)\n",
        "\n",
        "    def __getitem__(self, ix: int) -> dict[str, torch.tensor]:\n",
        "        return self.data[ix]\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self.data)\n",
        "\n",
        "dataset = Dataset(tokenized_premises, tokenized_hypothesis,\n",
        "                           (data[\"focusing_question\"] for data in dataset['train']))"
      ],
      "id": "1b46bf79-b115-4028-9826-5b18ff3837cd"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b2090d22-79b3-4cf8-b5bc-3b91c5d80792"
      },
      "outputs": [],
      "source": [
        "train_ratio = 0.80\n",
        "n_total = len(snli_dataset)\n",
        "n_train = int(n_total * train_ratio)\n",
        "n_val = n_total - n_train\n",
        "\n",
        "train_dataset, val_dataset = random_split(snli_dataset, [n_train, n_val])\n",
        "\n",
        "batch_size = 16  # mentioned in the paper\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ],
      "id": "b2090d22-79b3-4cf8-b5bc-3b91c5d80792"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9c38c14b-d464-4401-b562-d06e738da088"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import BertModel, BertTokenizerFast\n",
        "from datasets import Dataset\n",
        "\n",
        "class Sbert(nn.Module):\n",
        "    def __init__(self, max_length: int = 128, num_classes: int = 1):\n",
        "        super().__init__()\n",
        "        self.max_length = max_length\n",
        "        self.bert_model = BertModel.from_pretrained('bert-base-uncased')\n",
        "        self.bert_tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n",
        "        # Change the output size to match the number of classes\n",
        "        self.linear = nn.Linear(self.bert_model.config.hidden_size * 3, num_classes)\n",
        "\n",
        "    def forward(self, data: Dataset) -> torch.tensor:\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "        premise_input_ids = data[\"premise_input_ids\"].to(device)\n",
        "        premise_attention_mask = data[\"premise_attention_mask\"].to(device)\n",
        "        hypothesis_input_ids = data[\"hypothesis_input_ids\"].to(device)\n",
        "        hypothesis_attention_mask = data[\"hypothesis_attention_mask\"].to(device)\n",
        "\n",
        "        out_premise = self.bert_model(premise_input_ids, premise_attention_mask)\n",
        "        out_hypothesis = self.bert_model(hypothesis_input_ids, hypothesis_attention_mask)\n",
        "        premise_embeds = out_premise.last_hidden_state\n",
        "        hypothesis_embeds = out_hypothesis.last_hidden_state\n",
        "\n",
        "        pooled_premise_embeds = mean_pool(premise_embeds, premise_attention_mask)\n",
        "        pooled_hypotheses_embeds = mean_pool(hypothesis_embeds, hypothesis_attention_mask)\n",
        "\n",
        "        # u, v, u*v, |u-v|\n",
        "        \"\"\"\n",
        "        embeds = torch.cat([pooled_premise_embeds, pooled_hypotheses_embeds,\n",
        "                            pooled_premise_embeds * pooled_hypotheses_embeds,\n",
        "                            torch.abs(pooled_premise_embeds - pooled_hypotheses_embeds)],\n",
        "                           dim=-1)\n",
        "\n",
        "        # u, v, |u-v|\n",
        "        \"\"\"\n",
        "        embeds = torch.cat([pooled_premise_embeds, pooled_hypotheses_embeds,\n",
        "                            torch.abs(pooled_premise_embeds - pooled_hypotheses_embeds)],\n",
        "                           dim=-1)\n",
        "        \"\"\"\n",
        "        # u, v, u*v\n",
        "        embeds = torch.cat([pooled_premise_embeds, pooled_hypotheses_embeds,\n",
        "                            pooled_premise_embeds * pooled_hypotheses_embeds],\n",
        "                           dim=-1)\n",
        "        \"\"\"\n",
        "\n",
        "        return self.linear(embeds)\n",
        "\n",
        "def mean_pool(token_embeds: torch.tensor, attention_mask: torch.tensor) -> torch.tensor:\n",
        "    in_mask = attention_mask.unsqueeze(-1).expand(token_embeds.size()).float()\n",
        "    pool = torch.sum(token_embeds * in_mask, 1) / torch.clamp(in_mask.sum(1), min=1e-9)\n",
        "\n",
        "    return pool\n",
        "\n"
      ],
      "id": "9c38c14b-d464-4401-b562-d06e738da088"
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import BertModel, BertTokenizerFast\n",
        "from datasets import Dataset\n",
        "\n",
        "class Sbert(nn.Module):\n",
        "    def __init__(self, max_length: int = 128, num_classes: int = 1):\n",
        "        super().__init__()\n",
        "        self.max_length = max_length\n",
        "        self.bert_model = BertModel.from_pretrained('bert-base-uncased')\n",
        "        self.bert_tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n",
        "        # Change the output size to match the number of classes\n",
        "        self.linear = nn.Linear(self.bert_model.config.hidden_size * 3, num_classes)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, data: Dataset) -> torch.tensor:\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "        premise_input_ids = data[\"premise_input_ids\"].to(device)\n",
        "        premise_attention_mask = data[\"premise_attention_mask\"].to(device)\n",
        "        hypothesis_input_ids = data[\"hypothesis_input_ids\"].to(device)\n",
        "        hypothesis_attention_mask = data[\"hypothesis_attention_mask\"].to(device)\n",
        "\n",
        "        out_premise = self.bert_model(premise_input_ids, premise_attention_mask)\n",
        "        out_hypothesis = self.bert_model(hypothesis_input_ids, hypothesis_attention_mask)\n",
        "        premise_embeds = out_premise.last_hidden_state\n",
        "        hypothesis_embeds = out_hypothesis.last_hidden_state\n",
        "\n",
        "        pooled_premise_embeds = mean_pool(premise_embeds, premise_attention_mask)\n",
        "        pooled_hypotheses_embeds = mean_pool(hypothesis_embeds, hypothesis_attention_mask)\n",
        "\n",
        "        # u, v, |u-v|\n",
        "\n",
        "        embeds = torch.cat([pooled_premise_embeds, pooled_hypotheses_embeds,\n",
        "                            torch.abs(pooled_premise_embeds - pooled_hypotheses_embeds)],\n",
        "                           dim=-1)\n",
        "        output = self.linear(embeds)\n",
        "        output = self.sigmoid(output)  # Apply sigmoid activation\n",
        "        binary_output = torch.round(output)  # Round to the nearest integer (0 or 1)\n",
        "\n",
        "        return binary_output\n",
        "\n",
        "def mean_pool(token_embeds: torch.tensor, attention_mask: torch.tensor) -> torch.tensor:\n",
        "    in_mask = attention_mask.unsqueeze(-1).expand(token_embeds.size()).float()\n",
        "    pool = torch.sum(token_embeds * in_mask, 1) / torch.clamp(in_mask.sum(1), min=1e-9)\n",
        "\n",
        "    return pool\n",
        "\n"
      ],
      "metadata": {
        "id": "5VB2o0_jml-Z"
      },
      "id": "5VB2o0_jml-Z",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a8bf93eb-72f0-4b89-a99d-5e820cbd818a"
      },
      "outputs": [],
      "source": [
        "model = Sbert()\n",
        "#  optimizer, lr, num_warmup steps have been picked from the paper\n",
        "#optimizer = torch.optim.Adam(model.parameters(), lr=2e-5)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=2e-5, weight_decay=0.01)\n",
        "\n",
        "total_steps = len(train_dataset) // batch_size\n",
        "warmup_steps = int(0.1 * total_steps)\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=warmup_steps,\n",
        "                                            num_training_steps=total_steps - warmup_steps)\n",
        "\n",
        "#loss_fn = torch.nn.CrossEntropyLoss()\n",
        "loss_fn = torch.nn.BCEWithLogitsLoss()"
      ],
      "id": "a8bf93eb-72f0-4b89-a99d-5e820cbd818a"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "94a78a75-4b7f-46cf-978a-bed7be2f2acd"
      },
      "outputs": [],
      "source": [
        "model = model.to(device)"
      ],
      "id": "94a78a75-4b7f-46cf-978a-bed7be2f2acd"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "14fdb6e9-eaeb-43fd-af5e-a86ddaac32f4"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\n",
        "from typing import Callable\n",
        "import torch\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "def get_train_step_fn(\n",
        "    model: torch.nn.Module, optimizer: torch.optim.Optimizer,\n",
        "    scheduler: torch.optim.lr_scheduler.LambdaLR, loss_fn: torch.nn.BCEWithLogitsLoss\n",
        ") -> Callable[[torch.tensor, torch.tensor], tuple[float, np.ndarray, np.ndarray]]:\n",
        "\n",
        "    def train_step_fn(x: torch.tensor, y: torch.tensor) -> tuple[float, np.ndarray, np.ndarray]:\n",
        "        model.train()\n",
        "        yhat = model(x)\n",
        "        loss = loss_fn(yhat.squeeze(), y.float())\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "        optimizer.zero_grad()\n",
        "        #print(yhat)\n",
        "        # Convert predictions to labels\n",
        "        #preds = torch.round(torch.sigmoid(yhat)).cpu().numpy()\n",
        "        preds = torch.round(torch.sigmoid(yhat)).detach().cpu().numpy()\n",
        "        #print(preds)\n",
        "        return loss.item(), preds, y.cpu().numpy()\n",
        "\n",
        "    return train_step_fn\n",
        "\n",
        "def get_val_step_fn(\n",
        "    model: torch.nn.Module, loss_fn: torch.nn.BCEWithLogitsLoss\n",
        ") -> Callable[[torch.tensor, torch.tensor], tuple[float, np.ndarray, np.ndarray]]:\n",
        "\n",
        "    def val_step_fn(x: torch.tensor, y: torch.tensor) -> tuple[float, np.ndarray, np.ndarray]:\n",
        "        model.eval()\n",
        "        yhat = model(x)\n",
        "        loss = loss_fn(yhat.squeeze(), y.float())\n",
        "\n",
        "        # Convert predictions to labels\n",
        "        #preds = torch.round(torch.sigmoid(yhat)).cpu().numpy()\n",
        "        preds = torch.round(torch.sigmoid(yhat)).detach().cpu().numpy()\n",
        "        return loss.item(), preds, y.cpu().numpy()\n",
        "\n",
        "    return val_step_fn\n",
        "\n",
        "def mini_batch(\n",
        "    dataloader: DataLoader,\n",
        "    step_fn: Callable[[torch.tensor, torch.tensor], tuple[float, np.ndarray, np.ndarray]],\n",
        "    is_training: bool = True\n",
        ") -> tuple[float, float, float, float]:\n",
        "\n",
        "    mini_batch_losses = []\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    if is_training:\n",
        "        print(\"\\nTraining ...\")\n",
        "    else:\n",
        "        print(\"\\nValidating ...\")\n",
        "    n_steps = len(dataloader)\n",
        "    for i, data in enumerate(dataloader):\n",
        "        x, y = data, data[\"label\"].to(device)\n",
        "\n",
        "        loss, preds, labels = step_fn(x, y)\n",
        "        mini_batch_losses.append(loss)\n",
        "        all_preds.extend(preds)\n",
        "        all_labels.extend(labels)\n",
        "\n",
        "        if i % (batch_size * 100) == 0:\n",
        "            print(f\"step {i:>5}/{n_steps}, loss = {loss: .5f}\")\n",
        "\n",
        "    # Calculate metrics\n",
        "    accuracy = accuracy_score(all_labels, all_preds)\n",
        "    precision = precision_score(all_labels, all_preds, average='weighted')\n",
        "    recall = recall_score(all_labels, all_preds, average='weighted')\n",
        "    f1 = f1_score(all_labels, all_preds, average='weighted')\n",
        "\n",
        "    return np.mean(mini_batch_losses), mini_batch_losses, accuracy, precision, recall, f1, all_preds, all_labels\n",
        "\n",
        "n_epochs = 10  # mentioned in the paper\n",
        "\n",
        "train_step_fn = get_train_step_fn(model, optimizer, scheduler, loss_fn)\n",
        "val_step_fn = get_val_step_fn(model, loss_fn)\n",
        "\n",
        "# Initialize lists to store metrics\n",
        "train_losses, train_mini_batch_losses, train_accuracies, train_precisions, train_recalls, train_f1s = [], [], [], [], [], []\n",
        "val_losses, val_mini_batch_losses, val_accuracies, val_precisions, val_recalls, val_f1s, val_trues, val_preds = [], [], [], [], [], [], [], []\n",
        "\n",
        "for epoch in range(1, n_epochs + 1):\n",
        "    # Training\n",
        "    train_loss,  _train_mini_batch_losses, train_accuracy, train_precision, train_recall, train_f1, _, _= mini_batch(train_dataloader, train_step_fn)\n",
        "    train_losses.append(train_loss)\n",
        "    train_mini_batch_losses += _train_mini_batch_losses\n",
        "    train_accuracies.append(train_accuracy)\n",
        "    train_precisions.append(train_precision)\n",
        "    train_recalls.append(train_recall)\n",
        "    train_f1s.append(train_f1)\n",
        "\n",
        "    # Validation\n",
        "    with torch.no_grad():\n",
        "        val_loss, _val_mini_batch_losses, val_accuracy, val_precision, val_recall, val_f1, val_pred, val_true = mini_batch(val_dataloader, val_step_fn, is_training=False)\n",
        "        val_losses.append(val_loss)\n",
        "        val_mini_batch_losses += _val_mini_batch_losses\n",
        "        val_accuracies.append(val_accuracy)\n",
        "        val_precisions.append(val_precision)\n",
        "        val_recalls.append(val_recall)\n",
        "        val_f1s.append(val_f1)\n",
        "        val_trues.append(val_true)\n",
        "        val_preds.append(val_pred)\n",
        "\n",
        "    # Optionally, print epoch results\n",
        "    print(f'Epoch {epoch}/{n_epochs} - '\n",
        "          f'Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}, Train Precision: {train_precision:.4f}, Train Recall: {train_recall:.4f}, Train F1: {train_f1:.4f} - '\n",
        "          f'Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}, Val Precision: {val_precision:.4f}, Val Recall: {val_recall:.4f}, Val F1: {val_f1:.4f}')\n"
      ],
      "id": "14fdb6e9-eaeb-43fd-af5e-a86ddaac32f4"
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "window_size = 32\n",
        "\n",
        "train_mb_running_loss = []\n",
        "for i in range(len(train_mini_batch_losses)-window_size):\n",
        "    train_mb_running_loss.append(np.mean(train_mini_batch_losses[i:i+window_size]))\n",
        "\n",
        "val_mb_running_loss = []\n",
        "for i in range(len(val_mini_batch_losses)-window_size):\n",
        "    val_mb_running_loss.append(np.mean(val_mini_batch_losses[i:i+window_size]))\n",
        "\n",
        "fix, ax = plt.subplots(figsize=(6, 3))\n",
        "ax.plot(range(len(train_mb_running_loss)), train_mb_running_loss);"
      ],
      "metadata": {
        "id": "l2ueJfyKPeAr"
      },
      "id": "l2ueJfyKPeAr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encode(\n",
        "    input_texts: list[str], tokenizer: BertTokenizerFast, model: BertModel, device: str = \"cpu\"\n",
        ") -> torch.tensor:\n",
        "\n",
        "    model.eval()\n",
        "    tokenized_texts = tokenizer(input_texts, max_length=MAX_LENGTH,\n",
        "                                padding='max_length', truncation=True, return_tensors=\"pt\")\n",
        "    token_embeds = model(tokenized_texts[\"input_ids\"].to(device),\n",
        "                         tokenized_texts[\"attention_mask\"].to(device)).last_hidden_state\n",
        "    pooled_embeds = mean_pool(token_embeds, tokenized_texts[\"attention_mask\"].to(device))\n",
        "    return pooled_embeds"
      ],
      "metadata": {
        "id": "CsAvjATZvazl"
      },
      "id": "CsAvjATZvazl",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ee6f0e8f482a489f8872e7533650ece0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_998c8e2f043941ce88ce81dd7115eaba",
              "IPY_MODEL_fd6538776c014607a05e6c7509b9d804",
              "IPY_MODEL_222ad898257f4d2184d4dbce267f0227"
            ],
            "layout": "IPY_MODEL_c42bd8877dd543bea98f50fe86fc1ce0"
          }
        },
        "998c8e2f043941ce88ce81dd7115eaba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f5fd8c9b723640d3b9bac3958569af24",
            "placeholder": "​",
            "style": "IPY_MODEL_6324a7454ece41b9a2f50845499282f2",
            "value": "Generating train split: "
          }
        },
        "fd6538776c014607a05e6c7509b9d804": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_04c2f8b2d86040c08c34971f31a305f0",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9a8ccbdc79854684a9d70178e2183082",
            "value": 1
          }
        },
        "222ad898257f4d2184d4dbce267f0227": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c88988f31a49457a9d41d9fad5e4496e",
            "placeholder": "​",
            "style": "IPY_MODEL_c8884bcd07f240e3b6e4294fe8d93002",
            "value": " 2348/0 [00:00&lt;00:00, 38099.80 examples/s]"
          }
        },
        "c42bd8877dd543bea98f50fe86fc1ce0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f5fd8c9b723640d3b9bac3958569af24": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6324a7454ece41b9a2f50845499282f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "04c2f8b2d86040c08c34971f31a305f0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "9a8ccbdc79854684a9d70178e2183082": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c88988f31a49457a9d41d9fad5e4496e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c8884bcd07f240e3b6e4294fe8d93002": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}